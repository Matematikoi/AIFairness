{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: MDSS Classifier\n",
    "\n",
    "Detecting unfairness instances in subpopulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's include the demo preprocessing to use the identified subgroups in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'race': [0.0], 'age_cat': [0.0], 'sex': [0.0]}, 3.1526)\n",
      "({'sex': [1.0], 'race': [0.0]}, 3.3036)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, MDSSClassificationMetric\n",
    "from aif360.detectors import bias_scan\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_compas\n",
    "\n",
    "dataset_orig = load_preproc_data_compas()\n",
    "\n",
    "female_group = [{'sex': 1}]\n",
    "male_group = [{'sex': 0}]\n",
    "\n",
    "dataset_orig_df = pd.DataFrame(dataset_orig.features, columns=dataset_orig.feature_names)\n",
    "\n",
    "# Changes from one-hot encoding to categorical features\n",
    "age_cat = np.argmax(dataset_orig_df[['age_cat=Less than 25', 'age_cat=25 to 45',\n",
    "                                     'age_cat=Greater than 45']].values, axis=1).reshape(-1, 1)\n",
    "priors_count = np.argmax(dataset_orig_df[['priors_count=0', 'priors_count=1 to 3',\n",
    "                                          'priors_count=More than 3']].values, axis=1).reshape(-1, 1)\n",
    "c_charge_degree = np.argmax(dataset_orig_df[['c_charge_degree=M', 'c_charge_degree=F']].values, axis=1).reshape(-1, 1)\n",
    "\n",
    "features = np.concatenate((dataset_orig_df[['sex', 'race']].values, age_cat, priors_count,\n",
    "                           c_charge_degree, dataset_orig.labels), axis=1)\n",
    "feature_names = ['sex', 'race', 'age_cat', 'priors_count', 'c_charge_degree']\n",
    "\n",
    "# Creates a structured dataset with new format to train a logistic regression classifier\n",
    "df = pd.DataFrame(features, columns=feature_names + ['two_year_recid'])\n",
    "dataset = StandardDataset(df, label_name='two_year_recid', favorable_classes=[0],\n",
    "                 protected_attribute_names=['sex', 'race'],\n",
    "                 privileged_classes=[[1], [1]],\n",
    "                 instance_weights_name=None)\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', C=1.0, penalty='l2', random_state=0)\n",
    "clf.fit(dataset_orig_train.features, dataset_orig_train.labels.flatten())\n",
    "\n",
    "# Makes predictions on test set\n",
    "dataset_bias_test_prob = clf.predict_proba(dataset_orig_test.features)[:, 0]\n",
    "\n",
    "dataset_bias_test = dataset_orig_test.copy()\n",
    "dataset_bias_test.scores = dataset_bias_test_prob\n",
    "dataset_bias_test.labels = dataset_orig_test.labels\n",
    "\n",
    "# Input probability predictions to determine privileged and unprivileged subsets\n",
    "df = pd.DataFrame(dataset_orig_test.features, columns=dataset_orig_test.feature_names)\n",
    "df['observed'] = pd.Series(dataset_orig_test.labels.flatten(), index=df.index)\n",
    "df['probabilities'] = pd.Series(dataset_bias_test_prob, index=df.index)\n",
    "\n",
    "privileged_subset = bias_scan(df.iloc[:, :-2], df.observed, df.probabilities,\n",
    "                              favorable_value=dataset_orig_test.favorable_label,\n",
    "                              penalty=0.5, overpredicted=True)\n",
    "unprivileged_subset = bias_scan(df.iloc[:, :-2], df.observed, df.probabilities,\n",
    "                                favorable_value=dataset_orig_test.favorable_label,\n",
    "                                penalty=0.5, overpredicted=False)\n",
    "print(privileged_subset)\n",
    "print(unprivileged_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MDSS demostration detects two subrgroups among the dataset that are biased beyond the other subgroups:\n",
    "- 'race' = 0 (Not caucasian) + 'age_cat' = 0 (Less than 25) + 'sex' = 0 (Male)\n",
    "- 'race' = 0 (Not caucasian) + 'sex' = 1 (Female)\n",
    "\n",
    "The logistic regression model systematically underestimates the recidivism risk of individuals in the `Non-caucasian`, `less than 25`, `Male` subgroup whereas individuals belonging to the `Non-caucasian`, `Female` are assigned a higher risk than is actually observed. We refer to these subgroups as the `detected privileged group` and `detected unprivileged group` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare this detected groups with their counterparts using MDSS to analyze the different hypothesis.\n",
    "\n",
    "We create groups considering opposite 'race' and 'sex':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detected privileged group (group 1) and opposite group (group 2)\n",
    "group_1 = [{'sex': 0, 'race': 0, 'age_cat': 0}]\n",
    "group_2 = [{'sex': 1, 'race': 1, 'age_cat': 0}]\n",
    "\n",
    "# Detected unprivileged group (group 3) and opposite group (group 4)\n",
    "group_3 = [{'sex': 1, 'race': 0}]\n",
    "group_4 = [{'sex': 0, 'race': 1}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st case: detected privileged group ('sex', 'race', and 'age_cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to analyze through the MDSS classifier, we first need to create a new standard dataset with 'age_cat' also as a protected attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.449811\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(features, columns=feature_names + ['two_year_recid'])\n",
    "dataset_pg = StandardDataset(df, label_name='two_year_recid', favorable_classes=[0],\n",
    "                 protected_attribute_names=['sex', 'race', 'age_cat'],\n",
    "                 privileged_classes=[[1], [1], [0]],\n",
    "                 instance_weights_name=None)\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_pg.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "metric_test = BinaryLabelDatasetMetric(dataset_orig_test,\n",
    "                             unprivileged_groups=group_2,\n",
    "                             privileged_groups=group_1)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_test.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the classifier, and performing a simple mean difference bias, we can see that there is a considerable difference between the defined groups.\n",
    "\n",
    "Let's now train a logistic regression model, make predictions and build a bias dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs', C=1.0, penalty='l2', random_state=0)\n",
    "clf.fit(dataset_orig_train.features, dataset_orig_train.labels.flatten())\n",
    "\n",
    "dataset_bias_test_prob = clf.predict_proba(dataset_orig_test.features)[:, 0]\n",
    "\n",
    "df = pd.DataFrame(dataset_orig_test.features, columns=dataset_orig_test.feature_names)\n",
    "df['observed'] = pd.Series(dataset_orig_test.labels.flatten(), index=df.index)\n",
    "df['probabilities'] = pd.Series(dataset_bias_test_prob, index=df.index)\n",
    "\n",
    "dataset_bias_test = dataset_orig_test.copy()\n",
    "dataset_bias_test.scores = dataset_bias_test_prob\n",
    "dataset_bias_test.labels = dataset_orig_test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in hand, we can now perform the MDSS classification metric.\n",
    "\n",
    "The idea of the method is to build apriori hypothesis. The MDSS bias will tell whether there is evidence to say that this logical statements have some fundamental basis.\n",
    "\n",
    "Let's see our first example:\n",
    "- We state that the unprivileged group is group 1 and that the privileged group is group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "# Case 1\n",
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=group_1,\n",
    "                                           privileged_groups=group_2)\n",
    "# Is there evidence that the hypothesized privileged group is actually privileged:\n",
    "group_2_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group_2_privileged_score)\n",
    "# Is there evidence that the hypothesized unprivileged group is actually unprivileged?\n",
    "group_1_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group_1_unprivileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these results, we can say the following:\n",
    "- There is no evidence to say that group 2 (Caucasian females below 25 y.o.) is privileged (0.0)\n",
    "- There is no evidence to say that group 1 (Non-caucasian males below 25 y.o.) is unprivileged (0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the opposite scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6526\n",
      "2.2644\n"
     ]
    }
   ],
   "source": [
    "# Case 2\n",
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=group_2,\n",
    "                                           privileged_groups=group_1)\n",
    "# Is there evidence that the hypothesized privileged group is actually privileged\n",
    "group_1_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group_1_privileged_score)\n",
    "# Is there evidence that the hypothesized unprivileged group is actually unprivileged\n",
    "group_2_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group_2_unprivileged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the results of the second case, we can say the following:\n",
    "- There is evidence to say that `group 1` (Non-caucasian males below 25 y.o.) `is privileged` (4.6526)\n",
    "- There is evidence to say that `group 2` (Caucasian females below 25 y.o.) `is unprivileged` (2.2644)\n",
    "\n",
    "These conclusions make sense considering that the group 1 subset was actually considered to be the most privileged group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd case: detected unprivileged group ('sex' and 'race')\n",
    "\n",
    "We perform the same steps for the detected unprivileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.069886\n",
      "-0.0\n",
      "0.263\n",
      "-0.0\n",
      "4.3036\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(features, columns=feature_names + ['two_year_recid'])\n",
    "dataset_ug = StandardDataset(df, label_name='two_year_recid', favorable_classes=[0],\n",
    "                 protected_attribute_names=['sex', 'race'],\n",
    "                 privileged_classes=[[1], [1]],\n",
    "                 instance_weights_name=None)\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_ug.split([0.7], shuffle=True, seed=0)\n",
    "\n",
    "# Privileged group (group 4) has lower observed recidivism than group 3\n",
    "metric_test = BinaryLabelDatasetMetric(dataset_orig_test,\n",
    "                             unprivileged_groups=group_3,\n",
    "                             privileged_groups=group_4)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_test.mean_difference())\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs', C=1.0, penalty='l2', random_state=0)\n",
    "clf.fit(dataset_orig_train.features, dataset_orig_train.labels.flatten())\n",
    "\n",
    "dataset_bias_test_prob = clf.predict_proba(dataset_orig_test.features)[:, 0]\n",
    "\n",
    "df = pd.DataFrame(dataset_orig_test.features, columns=dataset_orig_test.feature_names)\n",
    "df['observed'] = pd.Series(dataset_orig_test.labels.flatten(), index=df.index)\n",
    "df['probabilities'] = pd.Series(dataset_bias_test_prob, index=df.index)\n",
    "\n",
    "dataset_bias_test = dataset_orig_test.copy()\n",
    "dataset_bias_test.scores = dataset_bias_test_prob\n",
    "dataset_bias_test.labels = dataset_orig_test.labels\n",
    "\n",
    "# Case 1\n",
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=group_4,\n",
    "                                           privileged_groups=group_3)\n",
    "# Is there evidence that the hypothesized privileged group is actually privileged:\n",
    "group_3_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group_3_privileged_score)\n",
    "# Is there evidence that the hypothesized unprivileged group is actually unprivileged?\n",
    "group_4_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group_4_unprivileged_score)\n",
    "\n",
    "# Case 2\n",
    "mdss_classified = MDSSClassificationMetric(dataset_orig_test, dataset_bias_test,\n",
    "                                           unprivileged_groups=group_3,\n",
    "                                           privileged_groups=group_4)\n",
    "# Is there evidence that the hypothesized privileged group is actually privileged\n",
    "group_4_privileged_score = mdss_classified.score_groups(privileged=True)\n",
    "print(group_4_privileged_score)\n",
    "# Is there evidence that the hypothesized unprivileged group is actually unprivileged\n",
    "group_3_unprivileged_score = mdss_classified.score_groups(privileged=False)\n",
    "print(group_3_unprivileged_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking into account the size of the group and the magnitude of the deviation, mdss bias core has been able to tell us the following about the results:\n",
    "- There is no evidence to say that group 3 (Non-caucasian females) is privileged (0.0)\n",
    "- There is evidence to say that `group 4` (Caucasian males) `is unprivileged` (0.263)\n",
    "- There is no evidence to say that group 4 (Caucasian males) is privileged (0.0)\n",
    "- There is evidence to say that `group 3` (Non-caucasian females) `is unprivileged` (4.3036)\n",
    "\n",
    "Contrary to the other subgroup analysis, here we have evidence to say that both groups are unprivileged. However, its also important to look at the bias metric because considering this analysis, there is bias evidence to say that the group 3 is more unprivileged than the also unprivileged group 4.\n",
    "\n",
    "If we look at the mean difference collected before performing, we can see the number isn't far from 0, meaning that difference between defined groups isn't as big (considering the formerly analyzed group 1 and group 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aif360)",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0c5ced7753e77a483fec8ff7063075635521cce6e0bd54998c8f174742209dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
